{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is SVM Implementation using Dual formulation with SMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It was taking too long (3.5 hours as 12000 rows in multiclass and categorical dataset) to run the code so we have used a OvO technique and trained the model using each class in different browsers manually which reduced my time to 35 mins and stored the model using pickle library.\n",
    "###### I have included a trained model with this python notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "import copy\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction method on the basis of voting in OvO multiclass SVM\n",
    "def predict(predicted):\n",
    "    y_predicted = np.zeros((predicted.shape[0]))\n",
    "    for i in range(predicted.shape[0]):\n",
    "        y_predicted[i] = np.where(predicted[i] == max(predicted[i]))[0][0]\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label Encoding the prediction class\n",
    "def label_encoding(y):\n",
    "    y_encoded = np.zeros((y.shape[0]))\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] == \"not_recom\":                \n",
    "            y_encoded[i] = 0\n",
    "        elif y[i] == \"recommend\":                \n",
    "            y_encoded[i] = 1\n",
    "        elif y[i] == \"very_recom\":                \n",
    "            y_encoded[i] = 2\n",
    "        elif y[i] == \"priority\":                \n",
    "            y_encoded[i] = 3\n",
    "        elif y[i] == \"spec_prior\":                \n",
    "            y_encoded[i] = 4\n",
    "    return y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_check(predicted):\n",
    "    error = 0\n",
    "    for i in range(predicted.shape[0]):\n",
    "        check = np.where(predicted[i] == max(predicted[i]))[0][0]\n",
    "        if check == 0:\n",
    "            if y_test[i] != \"not_recom\":                \n",
    "                error += 1\n",
    "        elif check == 1:\n",
    "            if y_test[i] != \"recommend\":                \n",
    "                error += 1\n",
    "        elif check == 2:\n",
    "            if y_test[i] != \"very_recom\":\n",
    "                error += 1\n",
    "        elif check == 3:\n",
    "            if y_test[i] != \"priority\":\n",
    "                error += 1\n",
    "        elif check == 4:\n",
    "            if y_test[i] != \"spec_prior\":\n",
    "                error += 1\n",
    "    # print(error)\n",
    "    return (1-((error/predicted.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of SMO algorithm for calculating value of alpha and bias \n",
    "def SMO(X, y, C, tol=math.pow(10, -3), max_passes=5, degree=3):\n",
    "    # size of input vector in feature space\n",
    "    m = X.shape[0]\n",
    "    a = np.zeros((m, 1))\n",
    "    b = 0\n",
    "    passes = 0\n",
    "    E = np.zeros((m, 1))\n",
    "    a_old = copy.deepcopy(a)\n",
    "    # Polynomial Kernel\n",
    "    kernel = lambda xi, yi: math.pow((np.dot(xi.T, yi) + 1), degree)\n",
    "    while passes < max_passes:\n",
    "        num_changed_alphas = 0\n",
    "        for i in range(m):\n",
    "            E[i] = f_x(X, y, a, b, X[i, :], degree) - y[i]\n",
    "            if (y[i]*E[i] < -tol and a[i] < C) or (y[i]*E[i] > tol and a[i] > 0):\n",
    "                j = random.randrange(m)\n",
    "                while j == i:\n",
    "                    j = random.randrange(m)\n",
    "                E[j] = f_x(X, y, a, b, X[j, :], degree) - y[j]\n",
    "                # print(E[j])\n",
    "                a_old[i] = a[i]\n",
    "                a_old[j] = a[j]\n",
    "                if y[i] != y[j]:\n",
    "                    L = max(0, a[j] - a[i])\n",
    "                    H = min(C, C + a[j] - a[i])\n",
    "                else:\n",
    "                    L = max(0, a[i] + a[j] - C)\n",
    "                    H = min(C, a[i] + a[j])\n",
    "                if L == H:\n",
    "                    continue\n",
    "                # calculating the value of eeta\n",
    "                n = 2*kernel(X[i, :], X[j, :]) - kernel(X[i, :], X[i, :]) - kernel(X[j, :], X[j, :])\n",
    "                if n >= 0:\n",
    "                    continue\n",
    "                # updating the value of alpha j\n",
    "                a[j] = a[j] - ((y[j] * (E[i] - E[j])) / n)\n",
    "                if a[j] > H:\n",
    "                    a[j] = H\n",
    "                elif a[j] < L:\n",
    "                    a[j] = L\n",
    "                # print(a[j])\n",
    "                if abs(a[j] - a_old[j]) < tol:\n",
    "                    continue\n",
    "                # updating the value of alpha i\n",
    "                a[i] = a[i] + y[i]*y[j]*(a_old[j] - a[j])\n",
    "                # print(a[i])\n",
    "                # now need to calculate the bias term\n",
    "                b1 = b - E[i] - (y[i] * (a[i] - a_old[i]) * kernel(X[i, :], X[i, :])) - \\\n",
    "                     (y[j] * (a[j] - a_old[j]) * kernel(X[i, :], X[j, :]))\n",
    "                b2 = b - E[j] - (y[i] * (a[i] - a_old[i]) * kernel(X[i, :], X[j, :])) - \\\n",
    "                     (y[j] * kernel(X[j, :], X[j, :]) * (a[j] - a_old[j]))\n",
    "                if a[i] > 0 and a[i] < C:\n",
    "                    b = b1\n",
    "                elif a[j] > 0 and a[j] < C:\n",
    "                    b = b2\n",
    "                else:\n",
    "                    b = (b1 + b2) / 2\n",
    "                num_changed_alphas += 1\n",
    "            # End if\n",
    "        # End for\n",
    "        if num_changed_alphas == 0:\n",
    "            passes += 1\n",
    "        else:\n",
    "            passes = 0\n",
    "    # end while\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_x(X, y, a, b, x, degree):\n",
    "    predicted_value = 0.0\n",
    "    # using polynomial kernel\n",
    "    for k in range(X.shape[0]):\n",
    "        predicted_value += (a[k]*y[k]*((X[k, :].T@x + 1)**degree))\n",
    "    return predicted_value + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividind dataset wrt to each class e.g classes = ['not_recom', 'recommend'] for all 10 classes pair\n",
    "def combination(X_train, y_train, classes):\n",
    "    X_subclass = np.array([])\n",
    "    y_subclass = np.array([])\n",
    "    for j in range(X_train.shape[0]):\n",
    "        if classes[0] == y_train[j]:\n",
    "            X_subclass = np.append(X_subclass, np.array(X_train[j]), axis=0)\n",
    "            y_subclass = np.append(y_subclass, 1)\n",
    "        elif classes[1] == y_train[j]:\n",
    "            X_subclass = np.append(X_subclass, np.array(X_train[j]), axis=0)\n",
    "            y_subclass = np.append(y_subclass, -1)\n",
    "    return X_subclass, y_subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'Data_with_-5_20_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data and storing it in file system\n",
    "dataset = pd.read_csv('Nursery_edited.csv', delimiter=',', skiprows=0)\n",
    "y = dataset.iloc[:, -1:].values\n",
    "X = dataset.iloc[:, :-1].values\n",
    "# Performing\n",
    "ohe = OneHotEncoder(categories='auto')\n",
    "X_transformed = ohe.fit_transform(X).toarray()\n",
    "# Spliting the data in 80-20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.20, random_state=42)\n",
    "\n",
    "outfile1 = open(folder+'\\X_train.pkl','wb')\n",
    "pickle.dump(X_train,outfile1)\n",
    "outfile1.close()\n",
    "outfile1 = open(folder+'\\y_train.pkl','wb')\n",
    "pickle.dump(y_train,outfile1)\n",
    "outfile1.close()\n",
    "outfile1 = open(folder+'\\X_test.pkl','wb')\n",
    "pickle.dump(X_test,outfile1)\n",
    "outfile1.close()\n",
    "outfile1 = open(folder+'\\y_test.pkl','wb')\n",
    "pickle.dump(y_test,outfile1)\n",
    "outfile1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Storing the validation data wrt each class\n",
    "OvO = list(combinations(['not_recom', 'recommend', 'very_recom', 'priority', 'spec_prior'], 2))\n",
    "k = 0\n",
    "for i in OvO:\n",
    "    X_subclass, y_subclass = combination(X_train, y_train, i)\n",
    "    X_subclass = X_subclass.reshape((np.int(X_subclass.shape[0] / 27), 27))    \n",
    "    y_subclass = y_subclass.astype(np.int32)      \n",
    "    \n",
    "    outfile1 = open(folder+'/train'+str(k)+'.pkl','wb')\n",
    "    pickle.dump(X_subclass,outfile1)\n",
    "    outfile1.close()   \n",
    "    outfile2 = open(folder+'/test'+str(k)+'.pkl','wb')\n",
    "    pickle.dump(y_subclass,outfile2)\n",
    "    outfile2.close()\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainging and storing alpha and bias on file system\n",
    "# to increase the time by simultaneously running in different browsers\n",
    "k = 1\n",
    "infile = open(folder+'/train'+str(k)+'.pkl','rb')\n",
    "X_subclass = pickle.load(infile)\n",
    "infile.close()\n",
    "infile = open(folder+'/test'+str(k)+'.pkl','rb')\n",
    "y_subclass = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "alpha, bias = SMO(X_subclass, y_subclass, 0.1)\n",
    "\n",
    "filename = folder+'/alpha'+str(k)+'.pkl'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(alpha,outfile)\n",
    "outfile.close()\n",
    "filename = folder+'/bias'+str(k)+'.pkl'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(bias,outfile)\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Test data\n",
    "infile = open(folder+'/X_test.pkl','rb')\n",
    "X_test = pickle.load(infile)\n",
    "infile.close()\n",
    "infile = open(folder+'/y_test.pkl','rb')\n",
    "y_test = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6319845857418112\n",
      "1882.4346897602081\n"
     ]
    }
   ],
   "source": [
    "# implementation that takes stored trained model and run test on the test data\n",
    "predicted_values = np.zeros((y_test.shape[0], 5))\n",
    "OvO = list(combinations(['not_recom', 'recommend', 'very_recom', 'priority', 'spec_prior'], 2))\n",
    "start = time.time()\n",
    "k = 0\n",
    "for i in OvO:\n",
    "    #print(i)\n",
    "    filename = folder+'/alpha'+str(k)+'.pkl'\n",
    "    infile = open(filename,'rb')\n",
    "    alpha = pickle.load(infile)\n",
    "    infile.close\n",
    "    filename = folder+'/bias'+str(k)+'.pkl'\n",
    "    infile = open(filename,'rb')\n",
    "    bias = pickle.load(infile)\n",
    "    infile.close\n",
    "    infile = open(folder+'/train'+str(k)+'.pkl','rb')\n",
    "    X_subclass = pickle.load(infile)\n",
    "    infile.close()\n",
    "    infile = open(folder+'/test'+str(k)+'.pkl','rb')\n",
    "    y_subclass = pickle.load(infile)\n",
    "    infile.close()\n",
    "    k += 1\n",
    "    y_predict = np.zeros((y_test.shape[0], 1))\n",
    "    for l in range(X_test.shape[0]):\n",
    "        #print(f_x(X_subclass, y_subclass, alpha, bias, X_test[l, :], 3))\n",
    "        if f_x(X_subclass, y_subclass, alpha, bias, X_test[l, :], 3) >= 0:\n",
    "            y_predict[l] = 1.0\n",
    "        else:\n",
    "            y_predict[l] = -1.0\n",
    "    for j in range(y_predict.shape[0]):\n",
    "        if i[0] == \"not_recom\" and y_predict[j] == 1:\n",
    "            predicted_values[j][0] += 1\n",
    "        elif i[1] == \"not_recom\" and y_predict[j] == -1:\n",
    "            predicted_values[j][0] += 1\n",
    "        if i[0] == \"recommend\" and y_predict[j] == 1:\n",
    "            predicted_values[j][1] += 1\n",
    "        elif i[1] == \"recommend\" and y_predict[j] == -1:\n",
    "            predicted_values[j][1] += 1\n",
    "        if i[0] == \"very_recom\" and y_predict[j] == 1:\n",
    "            predicted_values[j][2] += 1\n",
    "        elif i[1] == \"very_recom\" and y_predict[j] == -1:\n",
    "            predicted_values[j][2] += 1\n",
    "        if i[0] == \"priority\" and y_predict[j] == 1:\n",
    "            predicted_values[j][3] += 1\n",
    "        elif i[1] == \"priority\" and y_predict[j] == -1:\n",
    "            predicted_values[j][3] += 1\n",
    "        if i[0] == \"spec_prior\" and y_predict[j] == 1:\n",
    "            predicted_values[j][4] += 1\n",
    "        elif i[1] == \"spec_prior\" and y_predict[j] == -1:\n",
    "            predicted_values[j][4] += 1\n",
    "print(accuracy_check(predicted_values))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 63.19845857418112\n"
     ]
    }
   ],
   "source": [
    "print('Final Accuracy:', accuracy_check(predicted_values)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix :\n",
      "[[764 104   4   0   0]\n",
      " [  0   6   0   0   0]\n",
      " [  0  44  18   0   0]\n",
      " [  0 334 259 217  47]\n",
      " [  0  89  59  15 635]]\n"
     ]
    }
   ],
   "source": [
    "final_predict = predict(predicted_values)\n",
    "y_encoded = label_encoding(y_test)\n",
    "cm = confusion_matrix(y_encoded, final_predict, labels=[0, 1, 2, 3, 4])\n",
    "print('Confusion matrix :')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      0.88      0.93       872\n",
      "     class 1       0.01      1.00      0.02         6\n",
      "     class 2       0.05      0.29      0.09        62\n",
      "     class 3       0.94      0.25      0.40       857\n",
      "     class 4       0.93      0.80      0.86       798\n",
      "\n",
      "    accuracy                           0.63      2595\n",
      "   macro avg       0.59      0.64      0.46      2595\n",
      "weighted avg       0.93      0.63      0.71      2595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4']\n",
    "print(classification_report(y_encoded, final_predict, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1723,    0],\n",
       "        [ 108,  764]],\n",
       "\n",
       "       [[2018,  571],\n",
       "        [   0,    6]],\n",
       "\n",
       "       [[2211,  322],\n",
       "        [  44,   18]],\n",
       "\n",
       "       [[1723,   15],\n",
       "        [ 640,  217]],\n",
       "\n",
       "       [[1750,   47],\n",
       "        [ 163,  635]]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class vs Class confusion matrices\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "multilabel_confusion_matrix(y_encoded, final_predict, labels=[0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### NOTE: The below cell will take approx. 3 hours to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "0.26086956521739135\n",
      "34\n",
      "0.26086956521739135\n",
      "34\n",
      "0.26086956521739135\n",
      "34\n",
      "0.26086956521739135\n",
      "32\n",
      "0.30434782608695654\n",
      "30\n",
      "0.34782608695652173\n",
      "33\n",
      "0.28260869565217395\n",
      "22\n",
      "0.5217391304347826\n",
      "14\n",
      "0.6956521739130435\n",
      "3\n",
      "0.9347826086956522\n",
      "20.522088766098022\n"
     ]
    }
   ],
   "source": [
    "# This is complete implementation that is training and prediction without storing \n",
    "# cross validation   \n",
    "C = [0.01, 0.1, 1, 50]\n",
    "c_accuracy = [0,0,0,0]\n",
    "predicted_values = np.zeros((y_test.shape[0], 5))\n",
    "p = 0\n",
    "a = {}\n",
    "b = {}\n",
    "OvO = list(combinations(['not_recom', 'recommend', 'very_recom', 'priority', 'spec_prior'], 2))\n",
    "start = time.time()\n",
    "for i in OvO:\n",
    "    start2 = time.time()\n",
    "    X_subclass, y_subclass = combination(X_train, y_train, i)\n",
    "    X_subclass = X_subclass.reshape((np.int(X_subclass.shape[0] / 27), 27))\n",
    "    y_subclass = y_subclass.astype(np.int32)\n",
    "\n",
    "    y_predict = np.zeros((y_test.shape[0], 1))\n",
    "    for c in C:\n",
    "        alpha, bias = SMO(X_subclass, y_subclass, c)\n",
    "        a[p] = alpha\n",
    "        b[p] = bias           \n",
    "        p += 1 \n",
    "\n",
    "        for l in range(X_test.shape[0]):\n",
    "            if f_x(X_subclass, y_subclass, alpha, bias, X_test[l, :], 3) >= 0:\n",
    "                y_predict[l] = 1.0\n",
    "            else:\n",
    "                y_predict[l] = -1.0\n",
    "\n",
    "        for j in range(y_predict.shape[0]):\n",
    "            if i[0] == \"not_recom\" and y_predict[j] == 1:\n",
    "                predicted_values[j][0] += 1\n",
    "            elif i[1] == \"not_recom\" and y_predict[j] == -1:\n",
    "                predicted_values[j][0] += 1\n",
    "            if i[0] == \"recommend\" and y_predict[j] == 1:\n",
    "                predicted_values[j][1] += 1\n",
    "            elif i[1] == \"recommend\" and y_predict[j] == -1:\n",
    "                predicted_values[j][1] += 1\n",
    "            if i[0] == \"very_recom\" and y_predict[j] == 1:\n",
    "                predicted_values[j][2] += 1\n",
    "            elif i[1] == \"very_recom\" and y_predict[j] == -1:\n",
    "                predicted_values[j][2] += 1\n",
    "            if i[0] == \"priority\" and y_predict[j] == 1:\n",
    "                predicted_values[j][3] += 1\n",
    "            elif i[1] == \"priority\" and y_predict[j] == -1:\n",
    "                predicted_values[j][3] += 1\n",
    "            if i[0] == \"spec_prior\" and y_predict[j] == 1:\n",
    "                predicted_values[j][4] += 1\n",
    "            elif i[1] == \"spec_prior\" and y_predict[j] == -1:\n",
    "                predicted_values[j][4] += 1\n",
    "    c_accuracy[p] = accuracy_check(predicted_values)\n",
    "    print(accuracy_check(predicted_values))\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
